name: Launch job
#run-name: ${{ github.actor }} is executing Launch job ðŸš€

on:
  workflow_call:
    inputs:
      runs_on:
        required: false
        type: string
        default: ubuntu-latest
    
  
jobs:
  launch-job:
    runs-on: ${{ inputs.runs_on }}
    env:
      REMOTE_HOST: ${{ secrets.REMOTE_HOST }}
      REMOTE_USER: ${{ secrets.REMOTE_USER }}
      REMOTE_GROUP: ${{ secrets.REMOTE_GROUP }}
      GPFS_SINGULARITY_IMAGE_REGISTRY_PATH: ${{ vars.GPFS_SINGULARITY_IMAGE_REGISTRY_PATH }}
      GPFS_JUPYTER_WORKING_DIR: ${{ vars.GPFS_JUPYTER_WORKING_DIR }}
      GPFS_MODELS_REGISTRY_PATH: ${{ vars.GPFS_MODELS_REGISTRY_PATH }}
      MLFLOW_TRACKING_SERVER_URL: ${{vars.MLFLOW_TRACKING_SERVER_URL}}
      PORT1: "8080"
      PORT2: "8888"
      
    steps:
      - uses: actions/checkout@v4
   
      - name: Set ENV variables
        run: |
          echo "JOB_REPO_NAME=${GITHUB_REPOSITORY#$GITHUB_REPOSITORY_OWNER/}" >> $GITHUB_ENV
          echo "JOB_NAME=${GITHUB_REPOSITORY#$GITHUB_REPOSITORY_OWNER/}-${{ github.run_id }}" >> $GITHUB_ENV
          echo "JOB_PATH=/gpfs/scratch/${{ secrets.REMOTE_GROUP }}/${{ secrets.REMOTE_USER }}/jobs/${GITHUB_REPOSITORY#$GITHUB_REPOSITORY_OWNER/}/${{ github.run_id }}" >> $GITHUB_ENV
          echo "JOB_SINGULARITY_IMAGE=$(echo ${GITHUB_REPOSITORY#$GITHUB_REPOSITORY_OWNER/}.sif | awk '{print tolower($0)}')" >> $GITHUB_ENV
      
      - name: Set Socket variables
        run: |
          export SOCKET1=${JOB_PATH}/socket${PORT1}.sock
          export SOCKET2=${JOB_PATH}/socket${PORT2}.sock
          echo "SOCKET1=$SOCKET1" >> $GITHUB_ENV
          echo "SOCKET2=$SOCKET2" >> $GITHUB_ENV
          echo "JOB_SSH_TUNNEL_COMMAND=ssh -N -L ${{ env.PORT1 }}:${SOCKET1} -L ${{ env.PORT2 }}:${SOCKET2} ${{ secrets.REMOTE_USER }}@${{ secrets.REMOTE_HOST }}" >> $GITHUB_ENV

      - name: Save job related env vars to file
        run: |
          env | grep -e '^JOB_' -e '^GPFS_' > src/job.env
      
      - name: Replace SBATCH Directives with env variables
        run: | 
          sed -i "s|\%JOB_NAME%|${JOB_NAME}|" src/launch.sh
          sed -i "s|\%JOB_PATH%|${JOB_PATH}|" src/launch.sh
                    
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          architecture: 'x64'
      - uses: webfactory/ssh-agent@v0.9.0
        with:
          ssh-private-key: ${{ secrets.SSH_PRIVATE_KEY }}

      - name: Display Python version
        run: python -c "import sys; print(sys.version)"

      - name: Install hpc rocket from source
        run: pip install hpc-rocket

      - name: Launch job
        run: |
          output=$(hpc-rocket launch rocket.yml)
          echo "SLURM_JOB_ID=$(echo "$output" | grep -oE 'job [0-9]+' | grep -oE '[0-9]+')" >> $GITHUB_ENV
      
      - name: Setup mlflow
        id: mlflow
        uses: langtech-bsc/action_rsync_mlflow@main
        with:
          experiment_name: ${GITHUB_REPOSITORY#$GITHUB_REPOSITORY_OWNER/}
          remote_host: ${{ secrets.REMOTE_HOST }}
          remote_user: ${{ secrets.REMOTE_USER }}
          remote_source_path: ${{ env.JOB_PATH }}/logs
          traking_url: 'https://jobs.mlflow.dev.aina.bsc.es'
          run_name: ${{ env.SLURM_JOB_ID }} 
          schedule: 'true'
      
      - name: Check Mlflow 
        run: | 
          if [ -z "${{ steps.mlflow.outputs.artifact_url }}" ]; then
            echo "Mlflow API is not available, please contact MLOps team or try running the workflow again"
            echo "If you running the workflow locally with act, ensure you have BSC VPN conneted"
            exit 1
          fi

      - name: Watch job
        id: watch
        run: | 
         #Live status
         echo "Check the logs at: ${{ steps.mlflow.outputs.artifact_url }}"
         echo "Keep in mind that synchronization may take a little bit"
         nohup $(while true; do
            # hpc-rocket status rocket.yml --jobid ${{ env.SLURM_JOB_ID }} 
            running=$(hpc-rocket status rocket.yml --jobid ${{ env.SLURM_JOB_ID }}  | grep "RUNNING" | wc -l)
            if [[ $running > 0 ]]
            then
              nohup ml_flow -t sync > ${{ steps.mlflow.outputs.sync_dir }}/mlflow.log 2>&1 < /dev/null &
              # export MLFLOW_PID=$!
              echo "mlflow_pid=$!" >> $GITHUB_OUTPUT
              cat $GITHUB_OUTPUT

              SLURM_JOB_NODE=$(ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null ${{ secrets.REMOTE_USER }}@${{ secrets.REMOTE_HOST }} "squeue -j ${{ env.SLURM_JOB_ID }}  -o '%R'" | tail -1)
              if [[ $SLURM_JOB_NODE == *"["* ]]; then
                  # Split by '['
                  IFS='[' read -r prefix range <<< "$SLURM_JOB_NODE"
                  # Split the range part by '-'
                  IFS='-' read -r start end <<< "$range"
                  # Remove ']' from the start variable
                  start=${start%]*}
                  # Join prefix with start
                  result="${prefix}${start}"
                  SLURM_JOB_NODE=$result
              fi

              # node=$(echo "$SLURM_JOB_NODE" | grep -oE '\[[0-9]*' | grep -oE '[0-9]*')
              # input_string=$(echo "$SLURM_JOB_NODE" | sed 's/\[[^]]*\]//g')
              # echo "$input_string$node"

              ssh -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null ${{ secrets.REMOTE_USER }}@${{ secrets.REMOTE_HOST }} "rm -rf ${SOCKET1} ${SOCKET2}; ssh -Nf -L ${SOCKET1}:localhost:${PORT1} -L ${SOCKET2}:localhost:${PORT2} ${SLURM_JOB_NODE} && chmod 660 ${SOCKET1} ${SOCKET2} "
              echo "${{ env.JOB_SSH_TUNNEL_COMMAND }}" > ${{ steps.mlflow.outputs.sync_dir }}/tunnel.log 
              break
            fi
            sleep 5
          done)  > ./tmp 2>&1 < /dev/null &

          (while true; do
            hpc-rocket status rocket.yml --jobid ${{ env.SLURM_JOB_ID }} 
            sleep 20
          done) &
         hpc-rocket watch rocket.yml --jobid ${{ env.SLURM_JOB_ID }} 
        shell: bash
        continue-on-error: true

      - name: Kill mlflow
        if: always()
        run: | 
          kill -9 ${{ steps.watch.outputs.mlflow_pid }}
        continue-on-error: true

      - name: Check on success
        if: steps.watch.outcome == 'success'
        run: | 
          ml_flow -t stop
          exit 0

      - name: Check on failures
        if: steps.watch.outcome != 'success'
        run: | 
          ml_flow -t stop --failed
          exit 1
